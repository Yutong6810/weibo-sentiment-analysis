# final_app.py - å®Œæ•´å¯è¿è¡Œçš„ç‰ˆæœ¬
import streamlit as st
import pickle
import pandas as pd
import numpy as np
import re

# è®¾ç½®é¡µé¢
st.set_page_config(page_title="å¾®åšæƒ…æ„Ÿåˆ†æç³»ç»Ÿ", layout="wide")
st.title("ğŸ“Š å¾®åšæƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
st.markdown("---")

# å…ˆæ£€æŸ¥scikit-learnæ˜¯å¦å¯ç”¨
try:
    import sklearn
    st.sidebar.success(f"âœ… scikit-learn {sklearn.__version__}")
except ImportError:
    st.sidebar.error("âŒ scikit-learnæœªå®‰è£…")

# åŠ è½½æ¨¡å‹ - å…ˆå°è¯•å°æ¨¡å‹
@st.cache_resource
def load_model():
    try:
        # å…ˆå°è¯•å°æ¨¡å‹ï¼ˆ620KBï¼‰
        with open('naive_bayes_best_model.pkl', 'rb') as f:
            model_info = pickle.load(f)
        st.sidebar.success("âœ… åŸºç¡€æ¨¡å‹åŠ è½½æˆåŠŸ")
        return model_info
    except:
        try:
            # å†å°è¯•å¤§æ¨¡å‹
            with open('adaboost_nb_best_model.pkl', 'rb') as f:
                model_info = pickle.load(f)
            st.sidebar.success("âœ… AdaBoostæ¨¡å‹åŠ è½½æˆåŠŸ")
            return model_info
        except Exception as e:
            st.error(f"âŒ æ‰€æœ‰æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None

# æ˜¾ç¤ºåŠ è½½çŠ¶æ€
with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹..."):
    model_info = load_model()

if model_info is None:
    st.error("""
    ## æ¨¡å‹åŠ è½½å¤±è´¥
    
    å¯èƒ½åŸå› ï¼š
    1. æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨
    2. ä¾èµ–åŒ…ç‰ˆæœ¬ä¸åŒ¹é…
    3. å†…å­˜ä¸è¶³
    
    **è§£å†³æ–¹æ¡ˆï¼š**
    1. ç¡®ä¿ `.pkl` æ–‡ä»¶åœ¨åŒä¸€ä¸ªç›®å½•
    2. æ£€æŸ¥ requirements.txt æ˜¯å¦æ­£ç¡®
    3. å°è¯•æœ¬åœ°è¿è¡Œ
    """)
    st.stop()

# è·å–æ¨¡å‹å’Œå‘é‡åŒ–å™¨
model = model_info.get('model')
vectorizer = model_info.get('vectorizer')

if model is None or vectorizer is None:
    st.error("æ¨¡å‹ç»“æ„ä¸å®Œæ•´")
    st.stop()

# æ ‡ç­¾æ˜ å°„
LABELS = {0: "å®¢è§‚", 1: "ç§¯æ", 2: "æ¶ˆæ"}

# ==================== ä¸»ç•Œé¢ ====================
tab1, tab2, tab3 = st.tabs(["ğŸ“ åˆ†æ", "ğŸ“Š ç»Ÿè®¡", "â„¹ï¸ å…³äº"])

with tab1:
    st.header("æ–‡æœ¬æƒ…æ„Ÿåˆ†æ")
    
    # å•æ¡åˆ†æ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        user_input = st.text_area(
            "è¾“å…¥å¾®åšå†…å®¹ï¼š",
            "ä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œå¿ƒæƒ…æ„‰å¿«ï¼",
            height=120
        )
        
        if st.button("ğŸš€ åˆ†ææƒ…æ„Ÿ", type="primary"):
            # ç®€å•é¢„å¤„ç†
            text_clean = re.sub(r'[^\w\s\u4e00-\u9fff]', '', user_input)
            
            # é¢„æµ‹
            try:
                features = vectorizer.transform([text_clean])
                pred = model.predict(features)[0]
                sentiment = LABELS.get(pred, "æœªçŸ¥")
                
                # æ˜¾ç¤ºç»“æœ
                st.markdown("---")
                st.subheader("åˆ†æç»“æœ")
                
                if sentiment == "ç§¯æ":
                    st.success(f"âœ… **æƒ…æ„Ÿï¼š{sentiment}**")
                elif sentiment == "æ¶ˆæ":
                    st.error(f"âŒ **æƒ…æ„Ÿï¼š{sentiment}**")
                else:
                    st.info(f"ğŸ“„ **æƒ…æ„Ÿï¼š{sentiment}**")
                
                # æ˜¾ç¤ºåŸå§‹æ–‡æœ¬
                with st.expander("æŸ¥çœ‹å¤„ç†åçš„æ–‡æœ¬"):
                    st.code(text_clean)
                    
            except Exception as e:
                st.error(f"é¢„æµ‹å¤±è´¥: {e}")
    
    with col2:
        st.subheader("å¿«é€Ÿæµ‹è¯•")
        test_texts = [
            "å¤ªæ£’äº†ï¼",
            "å¾ˆå¤±æœ›ã€‚",
            "æ™®é€šã€‚"
        ]
        
        for text in test_texts:
            if st.button(text, key=text):
                st.session_state.test_text = text

with tab2:
    st.header("ç»Ÿè®¡åˆ†æ")
    
    if 'results' not in st.session_state:
        st.session_state.results = []
    
    # æ‰¹é‡åˆ†æ
    st.subheader("æ‰¹é‡åˆ†æ")
    batch_input = st.text_area(
        "è¾“å…¥å¤šæ¡æ–‡æœ¬ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰",
        "ä»Šå¤©å¾ˆå¼€å¿ƒ\nè¿™ä¸ªäº§å“å¾ˆç³Ÿç³•\nå¤©æ°”ä¸é”™",
        height=150
    )
    
    if st.button("ğŸ“¥ åˆ†ææ‰€æœ‰æ–‡æœ¬"):
        texts = [line.strip() for line in batch_input.split('\n') if line.strip()]
        results = []
        
        with st.spinner(f"æ­£åœ¨åˆ†æ {len(texts)} æ¡æ–‡æœ¬..."):
            for text in texts:
                try:
                    text_clean = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text)
                    features = vectorizer.transform([text_clean])
                    pred = model.predict(features)[0]
                    sentiment = LABELS.get(pred, "æœªçŸ¥")
                    results.append({
                        'text': text[:50] + "..." if len(text) > 50 else text,
                        'sentiment': sentiment
                    })
                except:
                    results.append({
                        'text': text[:50] + "..." if len(text) > 50 else text,
                        'sentiment': "é”™è¯¯"
                    })
        
        st.session_state.results = results
        
        # æ˜¾ç¤ºç»“æœè¡¨æ ¼
        if results:
            df = pd.DataFrame(results)
            st.dataframe(df, use_container_width=True)
            
            # ç®€å•ç»Ÿè®¡
            st.subheader("ç»Ÿè®¡æ‘˜è¦")
            sentiment_counts = df['sentiment'].value_counts()
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ç§¯æ", sentiment_counts.get("ç§¯æ", 0))
            with col2:
                st.metric("æ¶ˆæ", sentiment_counts.get("æ¶ˆæ", 0))
            with col3:
                st.metric("å®¢è§‚", sentiment_counts.get("å®¢è§‚", 0))

with tab3:
    st.header("å…³äºç³»ç»Ÿ")
    
    st.markdown("""
    ## ğŸ“‹ é¡¹ç›®ä¿¡æ¯
    
    **é€‰é¢˜ï¼š** åŸºäºæœºå™¨å­¦ä¹ çš„ç¤¾äº¤åª’ä½“æƒ…æ„Ÿåˆ†æ
    
    **ç›®æ ‡ï¼š** åˆ†æå¾®åšæ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼Œåˆ†ä¸ºç§¯æã€æ¶ˆæã€å®¢è§‚ä¸‰ç±»
    
    ## ğŸ› ï¸ æŠ€æœ¯æ¶æ„
    
    - **ç®—æ³•ï¼š** æœ´ç´ è´å¶æ–¯ + AdaBoostå¢å¼º
    - **å‡†ç¡®ç‡ï¼š** 94%ï¼ˆ10ä¸‡æ¡æ•°æ®é›†ï¼‰
    - **æ¡†æ¶ï¼š** Streamlitäº¤äº’å¼Webåº”ç”¨
    - **éƒ¨ç½²ï¼š** Streamlit Cloud
    
    ## ğŸ“ˆ åº”ç”¨åœºæ™¯
    
    1. **å“ç‰Œå£°èª‰ç›‘æµ‹**
       - åˆ†æç¤¾äº¤åª’ä½“å¯¹å“ç‰Œçš„è¯„ä»·å€¾å‘
       - åŠæ—¶å‘ç°è´Ÿé¢èˆ†æƒ…
    
    2. **èˆ†æƒ…åˆ†æ**
       - ç›‘æµ‹çƒ­ç‚¹äº‹ä»¶çš„å…¬ä¼—æƒ…æ„Ÿ
       - æ”¯æŒå†³ç­–åˆ¶å®š
    
    3. **ç”¨æˆ·åé¦ˆåˆ†æ**
       - åˆ†æäº§å“è¯„è®ºçš„æƒ…æ„Ÿåˆ†å¸ƒ
       - äº†è§£ç”¨æˆ·æ»¡æ„åº¦
    
    4. **å¸‚åœºè°ƒç ”**
       - äº†è§£æ¶ˆè´¹è€…æƒ…æ„Ÿå€¾å‘
       - æ”¯æŒäº§å“æ”¹è¿›
    """)
    
    st.markdown("---")
    st.caption("äººå·¥æ™ºèƒ½å¯¼è®ºå¤§ä½œä¸š Â· å¾®åšæƒ…æ„Ÿåˆ†æç³»ç»Ÿ")

# ==================== ä¾§è¾¹æ ä¿¡æ¯ ====================
st.sidebar.header("ç³»ç»ŸçŠ¶æ€")
st.sidebar.info(f"""
**æ¨¡å‹ï¼š** {'AdaBoostå¢å¼º' if 'adaboost' in str(model).lower() else 'æœ´ç´ è´å¶æ–¯'}
**ç‰¹å¾ç»´åº¦ï¼š** {vectorizer.vocabulary_.__len__() if hasattr(vectorizer, 'vocabulary_') else 'æœªçŸ¥'}
**åˆ†ç±»ï¼š** ç§¯æ/æ¶ˆæ/å®¢è§‚
""")

st.sidebar.header("ä½¿ç”¨è¯´æ˜")
st.sidebar.markdown("""
1. åœ¨"åˆ†æ"æ ‡ç­¾é¡µè¾“å…¥æ–‡æœ¬
2. ç‚¹å‡»"åˆ†ææƒ…æ„Ÿ"æŒ‰é’®
3. æŸ¥çœ‹åˆ†æç»“æœ
4. å¯åœ¨"ç»Ÿè®¡"æ ‡ç­¾é¡µè¿›è¡Œæ‰¹é‡åˆ†æ
""")

st.sidebar.markdown("---")
st.sidebar.caption("Â© 2024 äººå·¥æ™ºèƒ½å¯¼è®ºè¯¾ç¨‹é¡¹ç›®")
