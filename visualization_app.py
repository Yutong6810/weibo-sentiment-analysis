# visualization_app.py - ç»Ÿä¸€ä¿®æ”¹ç‰ˆ

# æ·»åŠ BERTæ¨¡å‹éœ€è¦çš„åº“
import torch
from transformers import BertTokenizer, BertModel
import torch.nn as nn
import streamlit as st
import pickle
import jieba
import re
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter

# ========== ä¸­æ–‡å­—ä½“æ˜¾ç¤º ==========
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'KaiTi']
matplotlib.rcParams['axes.unicode_minus'] = False

# è®¾ç½®é¡µé¢
st.set_page_config(page_title="æƒ…æ„Ÿåˆ†æå¯è§†åŒ–ç³»ç»Ÿ", layout="wide")
st.title("ğŸ“Š å¾®åšæƒ…æ„Ÿåˆ†æå¯è§†åŒ–ç³»ç»Ÿ")
st.markdown("---")

# åˆå§‹åŒ–session state
if 'history' not in st.session_state:
    st.session_state.history = []
if 'results' not in st.session_state:
    st.session_state.results = []

# ==================== æ¨¡å‹åŠ è½½å‡½æ•° ====================

@st.cache_resource
def load_naive_bayes_model():
    """åŠ è½½æœ´ç´ è´å¶æ–¯æ¨¡å‹"""
    try:
        with open('naive_bayes_best_model.pkl', 'rb') as f:
            model_info = pickle.load(f)
        st.success("âœ… æœ´ç´ è´å¶æ–¯æ¨¡å‹åŠ è½½å®Œæˆï¼")
        return {
            'model': model_info['model'],
            'vectorizer': model_info['vectorizer'],
            'model_type': 'naive_bayes'
        }
    except Exception as e:
        st.error(f"âŒ æœ´ç´ è´å¶æ–¯æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

@st.cache_resource
def load_adaboost_nb_model():
    """åŠ è½½AdaBoostå¢å¼ºæœ´ç´ è´å¶æ–¯æ¨¡å‹"""
    try:
        with open('adaboost_nb_best_model.pkl', 'rb') as f:
            model_info = pickle.load(f)
        st.success("âœ… AdaBoostå¢å¼ºæœ´ç´ è´å¶æ–¯æ¨¡å‹åŠ è½½å®Œæˆï¼")
        return {
            'model': model_info['model'],
            'vectorizer': model_info['vectorizer'],
            'model_type': 'adaboost_nb'
        }
    except Exception as e:
        st.error(f"âŒ AdaBoostæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

@st.cache_resource
def load_bert_model():
    """åŠ è½½BERTæ·±åº¦å­¦ä¹ æ¨¡å‹"""
    st.info("æ­£åœ¨åŠ è½½BERTæ¨¡å‹ï¼Œé¦–æ¬¡åŠ è½½å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´...")
    try:
        # å®šä¹‰æ¨¡å‹ç»“æ„
        class BertSentimentClassifier(nn.Module):
            def __init__(self, bert_model_name='bert-base-chinese', num_classes=3):
                super(BertSentimentClassifier, self).__init__()
                self.bert = BertModel.from_pretrained(bert_model_name)
                self.dropout = nn.Dropout(0.1)
                self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)
            
            def forward(self, input_ids, attention_mask):
                outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
                pooled_output = outputs.pooler_output
                pooled_output = self.dropout(pooled_output)
                logits = self.classifier(pooled_output)
                return logits
        
        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint = torch.load('sentiment_model_fixed.pth', map_location=torch.device('cpu'))
        
        # åˆå§‹åŒ–æ¨¡å‹
        model = BertSentimentClassifier()
        
        # åŠ è½½æƒé‡
        if 'model_state_dict' in checkpoint:
            model_state_dict = checkpoint['model_state_dict']
            # ç§»é™¤"module."å‰ç¼€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            new_state_dict = {}
            for key, value in model_state_dict.items():
                if key.startswith('module.'):
                    new_key = key[7:]
                else:
                    new_key = key
                new_state_dict[new_key] = value
            model.load_state_dict(new_state_dict, strict=False)
        else:
            model.load_state_dict(checkpoint)
        
        model.eval()
        
        # åŠ è½½åˆ†è¯å™¨
        tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')
        
        st.success("âœ… BERTæ¨¡å‹åŠ è½½å®Œæˆï¼")
        return {
            'model': model,
            'tokenizer': tokenizer,
            'model_type': 'bert'
        }
    
    except Exception as e:
        st.error(f"âŒ BERTæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        st.code(traceback.format_exc())
        return None

# ç»Ÿä¸€æ ‡ç­¾æ˜ å°„
LABELS = {0: "å®¢è§‚", 1: "ç§¯æ", 2: "æ¶ˆæ"}
COLORS = {'ç§¯æ': '#4CAF50', 'æ¶ˆæ': '#F44336', 'å®¢è§‚': '#2196F3'}

# ==================== è¾…åŠ©å‡½æ•° ====================

def preprocess_text(text):
    """é¢„å¤„ç†æ–‡æœ¬"""
    # å»é™¤ç‰¹æ®Šå­—ç¬¦
    text_clean = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text)
    words = jieba.lcut(text_clean)
    processed = ' '.join(words)
    return processed

def analyze_text_naive_bayes(text, model_info):
    """ä½¿ç”¨æœ´ç´ è´å¶æ–¯æ¨¡å‹åˆ†ææ–‡æœ¬"""
    if model_info is None:
        return {'error': 'æœ´ç´ è´å¶æ–¯æ¨¡å‹æœªåŠ è½½æˆåŠŸ'}
    
    model = model_info['model']
    vectorizer = model_info['vectorizer']
    
    # é¢„å¤„ç†
    processed = preprocess_text(text)
    
    # æå–ç‰¹å¾
    features = vectorizer.transform([processed])
    
    # é¢„æµ‹
    pred = model.predict(features)[0]
    proba = model.predict_proba(features)[0]
    
    # ä½¿ç”¨ç»Ÿä¸€æ ‡ç­¾æ˜ å°„
    sentiment = LABELS.get(pred, "æœªçŸ¥")
    confidence = proba[pred]
    
    # è·å–æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
    prob_dict = {}
    for i, prob in enumerate(proba):
        label = LABELS.get(i, f"ç±»åˆ«{i}")
        prob_dict[label] = prob
    
    return {
        'text': text[:100] + "..." if len(text) > 100 else text,
        'full_text': text,
        'sentiment': sentiment,
        'confidence': confidence,
        'probabilities': prob_dict,
        'model_type': 'æœ´ç´ è´å¶æ–¯'
    }

def analyze_text_adaboost_nb(text, model_info):
    """ä½¿ç”¨AdaBoostå¢å¼ºæœ´ç´ è´å¶æ–¯æ¨¡å‹åˆ†ææ–‡æœ¬"""
    if model_info is None:
        return {'error': 'AdaBoostæ¨¡å‹æœªåŠ è½½æˆåŠŸ'}
    
    model = model_info['model']
    vectorizer = model_info['vectorizer']
    
    # é¢„å¤„ç†
    processed = preprocess_text(text)
    
    # æå–ç‰¹å¾
    features = vectorizer.transform([processed])
    
    # é¢„æµ‹
    pred = model.predict(features)[0]
    proba = model.predict_proba(features)[0]
    
    # ä½¿ç”¨ç»Ÿä¸€æ ‡ç­¾æ˜ å°„
    sentiment = LABELS.get(pred, "æœªçŸ¥")
    confidence = proba[pred]
    
    # è·å–æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
    prob_dict = {}
    for i, prob in enumerate(proba):
        label = LABELS.get(i, f"ç±»åˆ«{i}")
        prob_dict[label] = prob
    
    return {
        'text': text[:100] + "..." if len(text) > 100 else text,
        'full_text': text,
        'sentiment': sentiment,
        'confidence': confidence,
        'probabilities': prob_dict,
        'model_type': 'AdaBoostå¢å¼ºæœ´ç´ è´å¶æ–¯'
    }

def analyze_text_bert(text, model_info):
    """ä½¿ç”¨BERTæ¨¡å‹åˆ†ææ–‡æœ¬"""
    if model_info is None:
        return {'error': 'BERTæ¨¡å‹æœªåŠ è½½æˆåŠŸ'}
    
    model = model_info['model']
    tokenizer = model_info['tokenizer']
    
    # ä½¿ç”¨BERTåˆ†è¯å™¨å¤„ç†æ–‡æœ¬
    inputs = tokenizer(text, padding=True, truncation=True, max_length=128, return_tensors="pt")
    
    # é¢„æµ‹
    with torch.no_grad():
        outputs = model(inputs['input_ids'], inputs['attention_mask'])
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
        predicted_class = torch.argmax(probabilities, dim=1).item()
        confidence = probabilities[0][predicted_class].item()
    
    # BERTæ¨¡å‹çš„åŸå§‹æ ‡ç­¾é¡ºåº
    bert_labels = ["æ¶ˆæ", "å®¢è§‚", "ç§¯æ"] 
    
    sentiment = bert_labels[predicted_class]
    
    # è·å–æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
    prob_list = probabilities[0].tolist()
    prob_dict = {bert_labels[i]: prob_list[i] for i in range(len(bert_labels))}
    
    return {
        'text': text[:100] + "..." if len(text) > 100 else text,
        'full_text': text,
        'sentiment': sentiment,
        'confidence': confidence,
        'probabilities': prob_dict,
        'model_type': 'BERT'
    }

def analyze_text(text, model_choice):
    """æ ¹æ®æ¨¡å‹é€‰æ‹©åˆ†ææ–‡æœ¬"""
    if model_choice == "æœ´ç´ è´å¶æ–¯ (åŸºç¡€)":
        if 'nb_model' not in st.session_state:
            st.session_state.nb_model = load_naive_bayes_model()
        return analyze_text_naive_bayes(text, st.session_state.nb_model)
    
    elif model_choice == "é›†æˆå­¦ä¹ : AdaBoostå¢å¼ºæœ´ç´ è´å¶æ–¯":
        if 'adaboost_model' not in st.session_state:
            st.session_state.adaboost_model = load_adaboost_nb_model()
        return analyze_text_adaboost_nb(text, st.session_state.adaboost_model)
    
    elif model_choice == "æ·±åº¦å­¦ä¹ : BERTæƒ…æ„Ÿåˆ†ææ¨¡å‹":
        if 'bert_model' not in st.session_state:
            st.session_state.bert_model = load_bert_model()
        return analyze_text_bert(text, st.session_state.bert_model)
    
    else:
        return {'error': 'æœªçŸ¥æ¨¡å‹é€‰æ‹©'}

# ==================== ä¾§è¾¹æ  ====================
st.sidebar.header("âš™ï¸ æ¨¡å‹é€‰æ‹©")
model_choice = st.sidebar.selectbox(
    "é€‰æ‹©åˆ†ææ¨¡å‹",
    ["æœ´ç´ è´å¶æ–¯ (åŸºç¡€)",
     "é›†æˆå­¦ä¹ : AdaBoostå¢å¼ºæœ´ç´ è´å¶æ–¯",
     "æ·±åº¦å­¦ä¹ : BERTæƒ…æ„Ÿåˆ†ææ¨¡å‹"]
)

st.sidebar.header("ğŸ“‹ æ‰¹é‡åˆ†æ")
batch_input = st.sidebar.text_area(
    "è¾“å…¥å¤šæ¡æ–‡æœ¬ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰",
    "ä»Šå¤©å¾ˆå¼€å¿ƒï¼\nè¿™ä¸ªäº§å“å¾ˆç³Ÿç³•\nå¤©æ°”ä¸é”™\næœåŠ¡æ€åº¦å¾ˆå¥½\nç”µå½±ä¸å¥½çœ‹",
    height=150
)

if st.sidebar.button("ğŸ“¥ æ‰¹é‡åˆ†æ", type="secondary"):
    texts = [line.strip() for line in batch_input.split('\n') if line.strip()]
    if texts:
        with st.spinner(f"æ­£åœ¨æ‰¹é‡åˆ†æ {len(texts)} æ¡æ–‡æœ¬..."):
            for text in texts:
                result = analyze_text(text, model_choice)
                if 'error' not in result:
                    st.session_state.history.append(text)
                    st.session_state.results.append(result)
            st.sidebar.success(f"âœ… æ‰¹é‡åˆ†æå®Œæˆï¼åˆ†æäº† {len(texts)} æ¡æ–‡æœ¬")
    else:
        st.sidebar.warning("è¯·è¾“å…¥æ–‡æœ¬å†…å®¹")

# æ¸…ç©ºå†å²æŒ‰é’®
if st.sidebar.button("ğŸ—‘ï¸ æ¸…ç©ºå†å²è®°å½•"):
    st.session_state.history = []
    st.session_state.results = []
    st.rerun()

# ==================== ä¸»ç•Œé¢ ====================
tab1, tab2, tab3 = st.tabs(["ğŸ”¤ å•æ¡åˆ†æ", "ğŸ“ˆ å¯è§†åŒ–", "ğŸ“‹ å†å²è®°å½•"])

with tab1:
    st.subheader("å•æ¡æ–‡æœ¬æƒ…æ„Ÿåˆ†æ")
    col1, col2 = st.columns([2, 1])
    
    with col1:
        user_input = st.text_area(
            "è¯·è¾“å…¥å¾®åšå†…å®¹ï¼š",
            "ä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œå¿ƒæƒ…æ„‰å¿«ï¼",
            height=120,
            key="single_input"
        )
        
        if st.button("ğŸš€ åˆ†ææƒ…æ„Ÿ", type="primary", key="single"):
            if user_input.strip():
                result = analyze_text(user_input, model_choice)
                
                if 'error' not in result:
                    sentiment = result['sentiment']
                    confidence = result['confidence']
                    
                    # æ˜¾ç¤ºç»“æœ
                    if sentiment == "ç§¯æ":
                        st.success(f"âœ… **æƒ…æ„Ÿï¼š{sentiment}** (ç½®ä¿¡åº¦ï¼š{confidence:.2%})")
                    elif sentiment == "æ¶ˆæ":
                        st.error(f"âŒ **æƒ…æ„Ÿï¼š{sentiment}** (ç½®ä¿¡åº¦ï¼š{confidence:.2%})")
                    else:
                        st.info(f"ğŸ“„ **æƒ…æ„Ÿï¼š{sentiment}** (ç½®ä¿¡åº¦ï¼š{confidence:.2%})")
                    
                    # æ˜¾ç¤ºè¯¦ç»†æ¦‚ç‡
                    with st.expander("æŸ¥çœ‹è¯¦ç»†æ¦‚ç‡"):
                        for label, prob in result['probabilities'].items():
                            st.write(f"{label}: {prob:.2%}")
                    
                    # ä¿å­˜ç»“æœ
                    st.session_state.history.append(user_input)
                    st.session_state.results.append(result)
                else:
                    st.error(f"åˆ†æå¤±è´¥: {result['error']}")
            else:
                st.warning("è¯·è¾“å…¥æ–‡æœ¬å†…å®¹")
    
    with col2:
        st.subheader("ğŸ“Š å½“å‰åˆ†å¸ƒ")
        if st.session_state.results:
            # ç»Ÿè®¡å½“å‰ç»“æœçš„æƒ…æ„Ÿåˆ†å¸ƒ
            sentiments = [r['sentiment'] for r in st.session_state.results]
            sentiment_counts = Counter(sentiments)
            
            # åˆ›å»ºé¥¼å›¾
            fig, ax = plt.subplots(figsize=(5, 4))
            labels = list(sentiment_counts.keys())
            sizes = list(sentiment_counts.values())
            
            if labels:  # ç¡®ä¿æœ‰æ•°æ®
                # ç¡®ä¿é¢œè‰²é¡ºåºä¸€è‡´
                colors = [COLORS.get(l, '#999') for l in labels]
                ax.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors)
                ax.set_title("å½“å‰æƒ…æ„Ÿåˆ†å¸ƒ")
                st.pyplot(fig)
            else:
                st.info("æš‚æ— åˆ†æè®°å½•")
        else:
            st.info("æš‚æ— åˆ†æè®°å½•")

with tab2:
    st.header("ğŸ“Š å¯è§†åŒ–åˆ†æ")
    
    if not st.session_state.results:
        st.warning("æš‚æ— åˆ†ææ•°æ®ï¼Œè¯·å…ˆåˆ†æä¸€äº›æ–‡æœ¬")
    else:
        # å‡†å¤‡æ•°æ®
        df = pd.DataFrame(st.session_state.results)
        
        # æ˜¾ç¤ºç»Ÿè®¡æ‘˜è¦
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»åˆ†ææ•°", len(df))
        with col2:
            positive = len(df[df['sentiment'] == 'ç§¯æ'])
            st.metric("ç§¯æ", positive)
        with col3:
            negative = len(df[df['sentiment'] == 'æ¶ˆæ'])
            st.metric("æ¶ˆæ", negative)
        with col4:
            neutral = len(df[df['sentiment'] == 'å®¢è§‚'])
            st.metric("å®¢è§‚", neutral)
        
        # å›¾è¡¨1ï¼šæƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾
        st.subheader("æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾")
        sentiment_counts = df['sentiment'].value_counts()
        fig1, ax1 = plt.subplots(figsize=(8, 6))
        
        # ç¡®ä¿æ ‡ç­¾å’Œé¢œè‰²é¡ºåº
        labels = sentiment_counts.index.tolist()
        sizes = sentiment_counts.values.tolist()
        colors = [COLORS.get(l, '#999') for l in labels]
        
        ax1.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors)
        ax1.set_title("æƒ…æ„Ÿåˆ†å¸ƒ")
        st.pyplot(fig1)
        
        # å›¾è¡¨2ï¼šæƒ…æ„Ÿåˆ†å¸ƒæŸ±çŠ¶å›¾
        st.subheader("æƒ…æ„Ÿåˆ†å¸ƒæŸ±çŠ¶å›¾")
        fig2, ax2 = plt.subplots(figsize=(8, 6))
        
        bars = ax2.bar(labels, sizes, color=colors)
        ax2.set_xlabel("æƒ…æ„Ÿ")
        ax2.set_ylabel("è¯„è®ºæ•°é‡")
        ax2.set_title("æƒ…æ„Ÿåˆ†å¸ƒç»Ÿè®¡")
        
        # åœ¨æŸ±å­ä¸Šæ˜¾ç¤ºæ•°å­—
        for bar in bars:
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                    f'{int(height)}', ha='center', va='bottom')
        
        st.pyplot(fig2)
        
        # å›¾è¡¨3ï¼šç½®ä¿¡åº¦åˆ†å¸ƒ
        if 'confidence' in df.columns:
            st.subheader("ç½®ä¿¡åº¦åˆ†å¸ƒ")
            fig3, ax3 = plt.subplots(figsize=(10, 4))
            
            # ä¸ºæ¯ç§æƒ…æ„Ÿåˆ›å»ºç½®ä¿¡åº¦åˆ†å¸ƒ
            for sentiment in df['sentiment'].unique():
                data = df[df['sentiment'] == sentiment]['confidence']
                if len(data) > 0:
                    ax3.hist(data, alpha=0.5, label=sentiment,
                            color=COLORS.get(sentiment), bins=10)
            
            ax3.set_xlabel("ç½®ä¿¡åº¦")
            ax3.set_ylabel("è¯„è®ºæ•°é‡")
            ax3.set_title("å„æƒ…æ„Ÿç½®ä¿¡åº¦åˆ†å¸ƒ")
            ax3.legend()
            ax3.grid(True, alpha=0.3)
            st.pyplot(fig3)
        
        # åº”ç”¨åœºæ™¯ç¤ºä¾‹
        st.subheader("ğŸ“± åº”ç”¨åœºæ™¯ç¤ºä¾‹")
        scenario_col1, scenario_col2 = st.columns(2)
        
        with scenario_col1:
            st.markdown("#### å“ç‰Œå£°èª‰ç›‘æµ‹")
            st.markdown("""
            - **ç›‘æµ‹å“ç‰Œ**åœ¨ç¤¾äº¤åª’ä½“ä¸Šçš„æåŠ
            - **åˆ†æç”¨æˆ·**å¯¹äº§å“çš„è¯„ä»·å€¾å‘
            - **åŠæ—¶å‘ç°**è´Ÿé¢èˆ†æƒ…å¹¶é¢„è­¦
            - **è·Ÿè¸ª**è¥é”€æ´»åŠ¨çš„æ•ˆæœ
            """)
            
            # ç¤ºä¾‹å“ç‰Œæ•°æ®
            brand_data = pd.DataFrame({
                'æƒ…æ„Ÿ': ['ç§¯æ', 'æ¶ˆæ', 'å®¢è§‚'],
                'æ•°é‡': [positive, negative, neutral]
            })
            
            fig_brand, ax_brand = plt.subplots(figsize=(6, 4))
            ax_brand.bar(brand_data['æƒ…æ„Ÿ'], brand_data['æ•°é‡'],
                        color=['#4CAF50', '#F44336', '#2196F3'])
            ax_brand.set_title("å“ç‰Œå£°èª‰åˆ†æ")
            ax_brand.set_ylabel("è¯„è®ºæ•°é‡")
            st.pyplot(fig_brand)
        
        with scenario_col2:
            st.markdown("#### èˆ†æƒ…åˆ†æ")
            st.markdown("""
            - **åˆ†æçƒ­ç‚¹äº‹ä»¶**çš„å…¬ä¼—æƒ…æ„Ÿ
            - **è¿½è¸ªæƒ…æ„Ÿ**éšæ—¶é—´çš„å˜åŒ–è¶‹åŠ¿
            - **è¯†åˆ«ä¸»è¦**æƒ…æ„Ÿé©±åŠ¨å› ç´ 
            - **æ”¯æŒå†³ç­–**åˆ¶å®šå’Œå±æœºç®¡ç†
            """)
            
            # ç®€å•çš„èˆ†æƒ…åˆ†æç¤ºä¾‹
            st.markdown("**èˆ†æƒ…åˆ†æç»“æœæ‘˜è¦ï¼š**")
            st.metric("æ€»ä½“ç§¯æç‡", f"{(positive/len(df)*100):.1f}%" if len(df) > 0 else "0%")
            st.metric("æ€»ä½“æ¶ˆæç‡", f"{(negative/len(df)*100):.1f}%" if len(df) > 0 else "0%")
            if 'confidence' in df.columns:
                st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{df['confidence'].mean():.2%}" if len(df) > 0 else "0%")

with tab3:
    st.header("ğŸ“‹ åˆ†æå†å²è®°å½•")
    
    if not st.session_state.results:
        st.info("æš‚æ— åˆ†æè®°å½•")
    else:
        # æ˜¾ç¤ºè¯¦ç»†è®°å½•
        st.subheader("è¯¦ç»†è®°å½•")
        
        # å¯æ’åºçš„è¡¨æ ¼
        df_display = pd.DataFrame(st.session_state.results)
        
        # ç¡®ä¿åŒ…å«å¿…è¦çš„åˆ—
        if 'text' in df_display.columns and 'sentiment' in df_display.columns and 'confidence' in df_display.columns:
            df_display = df_display[['text', 'sentiment', 'confidence', 'model_type']]
            df_display['confidence'] = df_display['confidence'].apply(lambda x: f"{x:.2%}")
            df_display.columns = ['æ–‡æœ¬', 'æƒ…æ„Ÿ', 'ç½®ä¿¡åº¦', 'æ¨¡å‹ç±»å‹']
            st.dataframe(df_display, use_container_width=True)
        else:
            st.warning("æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
        
        # å¯¼å‡ºé€‰é¡¹
        st.markdown("---")
        st.subheader("ğŸ“¤ å¯¼å‡ºç»“æœ")
        
        if st.button("ğŸ“„ å¯¼å‡ºä¸ºCSVæ–‡ä»¶"):
            df_export = pd.DataFrame(st.session_state.results)
            csv = df_export.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ä¸‹è½½CSVæ–‡ä»¶",
                data=csv,
                file_name="æƒ…æ„Ÿåˆ†æç»“æœ.csv",
                mime="text/csv"
            )

# ==================== åº•éƒ¨ä¿¡æ¯ ====================
st.sidebar.markdown("---")
st.sidebar.info("""
### ğŸ“Š ç³»ç»Ÿä¿¡æ¯
- **æ¨¡å‹ï¼š** æœ´ç´ è´å¶æ–¯ / AdaBoostå¢å¼º / BERT
- **åˆ†ç±»ï¼š** ç§¯æ / æ¶ˆæ / å®¢è§‚
- **ç»Ÿä¸€æ ‡ç­¾ï¼š** æ‰€æœ‰æ¨¡å‹ä½¿ç”¨ä¸­æ–‡æ ‡ç­¾

### ğŸ“ˆ åº”ç”¨åœºæ™¯
- **å“ç‰Œå£°èª‰ç›‘æµ‹**ï¼šåˆ†æç¤¾äº¤åª’ä½“å¯¹å“ç‰Œçš„è¯„ä»·å€¾å‘
- **èˆ†æƒ…åˆ†æ**ï¼šç›‘æµ‹å…¬ä¼—å¯¹çƒ­ç‚¹äº‹ä»¶çš„æƒ…æ„Ÿæ€åº¦
- **ç”¨æˆ·åé¦ˆåˆ†æ**ï¼šåˆ†æç”¨æˆ·è¯„è®ºçš„æƒ…æ„Ÿåˆ†å¸ƒ
- **å¸‚åœºè°ƒç ”**ï¼šäº†è§£æ¶ˆè´¹è€…å¯¹äº§å“çš„æƒ…æ„Ÿå€¾å‘
""")

st.sidebar.markdown("---")
st.sidebar.caption("äººå·¥æ™ºèƒ½å¯¼è®ºå¤§ä½œä¸š Â· æƒ…æ„Ÿåˆ†æå¯è§†åŒ–ç³»ç»Ÿ")